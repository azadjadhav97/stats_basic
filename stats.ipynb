{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "**Reasoning**:\n",
        "Import pandas and load the crop recommendation dataset into a DataFrame.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "UK0ZYpPCU_-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### **1. Calculate Mean, Median, and Mode**\n",
        "\n",
        "\n",
        "#### **Python Code:**\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "data = [10, 20, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = stats.mode(data).mode[0]\n",
        "\n",
        "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "e7RnW4ZKD6Ap",
        "outputId": "9ca7f691-5ca1-4cf7-a765-00352604e923"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "invalid index to scalar variable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-98350cd36790>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean: {mean}, Median: {median}, Mode: {mode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### **2. Compute Variance and Standard Deviation**\n",
        "#### **Formulae:**\n",
        "#- **Variance (σ²)** = \\( \\frac{\\sum (x_i - \\bar{x})^2}{n} \\)\n",
        "#- **Standard Deviation (σ)** = \\( \\sqrt{\\text{Variance}} \\)\n",
        "\n",
        "#### **Python Code:**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "data = [12, 15, 14, 10, 18, 20, 25, 30]\n",
        "\n",
        "variance = np.var(data, ddof=1)  # ddof=1 for sample variance\n",
        "std_dev = np.sqrt(variance)\n",
        "\n",
        "print(f\"Variance: {variance}, Standard Deviation: {std_dev}\")"
      ],
      "metadata": {
        "id": "SaAfBLpvFAuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **3. Create and Classify a Dataset (Nominal, Ordinal, Interval, Ratio)**\n",
        "#### **Classification:**\n",
        "```python\n",
        "dataset = {\n",
        "    \"Nominal\": [\"Red\", \"Blue\", \"Green\", \"Yellow\"],  # Categorical with no order\n",
        "    \"Ordinal\": [\"Low\", \"Medium\", \"High\"],  # Categorical with order\n",
        "    \"Interval\": [10, 20, 30, 40],  # Equal intervals, no true zero\n",
        "    \"Ratio\": [2.5, 5.0, 7.5, 10.0]  # Equal intervals, true zero\n",
        "}\n",
        "\n",
        "for category, values in dataset.items():\n",
        "    print(f\"{category}: {values}\")"
      ],
      "metadata": {
        "id": "tG4-s43KFIAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **4. Implement Random and Stratified Sampling**\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'Category': np.random.choice(['A', 'B', 'C'], 100),\n",
        "    'Values': np.random.randint(1, 100, 100)\n",
        "})\n",
        "\n",
        "# Simple Random Sampling\n",
        "random_sample = data.sample(n=10)\n",
        "\n",
        "# Stratified Sampling\n",
        "stratified_sample = data.groupby('Category', group_keys=False).apply(lambda x: x.sample(3))\n",
        "\n",
        "print(\"Random Sample:\\n\", random_sample)\n",
        "print(\"\\nStratified Sample:\\n\", stratified_sample)\n",
        "```"
      ],
      "metadata": {
        "id": "_Pvl4I4aFKx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **5. Calculate Range**\n",
        "```python\n",
        "def calculate_range(data):\n",
        "    return max(data) - min(data)\n",
        "\n",
        "data = [3, 7, 2, 9, 10, 15, 20]\n",
        "print(\"Range:\", calculate_range(data))\n",
        "```\n"
      ],
      "metadata": {
        "id": "xLVCb8WRFNIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### **6. Create a Histogram to Visualize Skewness**\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.random.normal(10, 5, 1000)  # Generating normal distribution\n",
        "\n",
        "plt.hist(data, bins=30, edgecolor='black')\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram\")\n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "DAn8pLLbFPkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **7. Calculate Skewness and Kurtosis**\n",
        "```python\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "data = np.random.normal(0, 1, 1000)\n",
        "\n",
        "print(\"Skewness:\", skew(data))\n",
        "print(\"Kurtosis:\", kurtosis(data))\n",
        "```\n"
      ],
      "metadata": {
        "id": "07LdMpQwFRQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **8. Generate Positive and Negative Skewness**\n",
        "```python\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Positively skewed data\n",
        "data_pos = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Negatively skewed data\n",
        "data_neg = np.random.normal(loc=-5, scale=2, size=1000)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "sns.histplot(data_pos, bins=30, ax=axes[0], kde=True)\n",
        "sns.histplot(data_neg, bins=30, ax=axes[1], kde=True)\n",
        "\n",
        "axes[0].set_title(\"Positively Skewed Data\")\n",
        "axes[1].set_title(\"Negatively Skewed Data\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d1tWvYEXFTrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **9. Calculate Covariance**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [2, 3, 5, 7, 11]\n",
        "\n",
        "cov_matrix = np.cov(x, y, bias=False)\n",
        "print(\"Covariance:\\n\", cov_matrix[0][1])\n",
        "```"
      ],
      "metadata": {
        "id": "p9oOtDaWFW0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### **10. Calculate Correlation Coefficient**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [2, 3, 5, 7, 11]\n",
        "\n",
        "correlation = np.corrcoef(x, y)[0, 1]\n",
        "print(\"Correlation Coefficient:\", correlation)"
      ],
      "metadata": {
        "id": "HDT__EhjFYm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **11. Scatter Plot of Two Variables**\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.random.randint(1, 100, 50)\n",
        "y = np.random.randint(1, 100, 50)\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel(\"Variable X\")\n",
        "plt.ylabel(\"Variable Y\")\n",
        "plt.title(\"Scatter Plot of Two Variables\")\n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "b3mUV_qIGOx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **12. Compare Simple Random and Systematic Sampling**\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "data = np.arange(1, 101)\n",
        "\n",
        "# Simple Random Sampling\n",
        "random_sample = np.random.choice(data, size=10, replace=False)\n",
        "\n",
        "# Systematic Sampling (every 10th element)\n",
        "systematic_sample = data[::10]\n",
        "\n",
        "print(\"Random Sample:\", random_sample)\n",
        "print(\"Systematic Sample:\", systematic_sample)\n",
        "```"
      ],
      "metadata": {
        "id": "Gv5ZCzNJGRSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **13. Calculate Mean, Median, and Mode for Grouped Data**\n",
        "```python\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Example of grouped data\n",
        "data = pd.DataFrame({\n",
        "    \"Class Interval\": [\"1-10\", \"11-20\", \"21-30\"],\n",
        "    \"Frequency\": [5, 15, 10]\n",
        "})\n",
        "\n",
        "# Calculate mean approximation using midpoint method\n",
        "data[\"Midpoint\"] = [5.5, 15.5, 25.5]\n",
        "mean = sum(data[\"Midpoint\"] * data[\"Frequency\"]) / sum(data[\"Frequency\"])\n",
        "\n",
        "# Median Class Calculation\n",
        "cumulative_frequency = data[\"Frequency\"].cumsum()\n",
        "median_class = data.iloc[(cumulative_frequency >= cumulative_frequency.max()/2).idxmax()]\n",
        "\n",
        "print(\"Grouped Mean:\", mean)\n",
        "print(\"Median Class:\", median_class)\n",
        "```"
      ],
      "metadata": {
        "id": "Wk3wtEbNGTy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **14. Simulate Data and Calculate Central Tendency & Dispersion**\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = np.random.randint(10, 100, 50)\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"Values\"])\n",
        "\n",
        "mean = df[\"Values\"].mean()\n",
        "median = df[\"Values\"].median()\n",
        "mode = df[\"Values\"].mode().values[0]\n",
        "std_dev = df[\"Values\"].std()\n",
        "variance = df[\"Values\"].var()\n",
        "\n",
        "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}, Std Dev: {std_dev}, Variance: {variance}\")"
      ],
      "metadata": {
        "id": "_GitvbyoGWtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "KIYlxaFSVAOt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {
        "id": "4763PB2OVESU"
      }
    },
    {
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset\n",
        "data = pd.DataFrame({\n",
        "    \"A\": np.random.randint(10, 100, 50),\n",
        "    \"B\": np.random.randint(20, 150, 50),\n",
        "    \"C\": np.random.normal(50, 15, 50)\n",
        "})\n",
        "\n",
        "# Summary statistics\n",
        "print(data.describe())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QhTH5dU5VFbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(data=data)\n",
        "plt.title(\"Boxplot of Dataset\")\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "hTCYDuGgVHfO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "print(\"Interquartile Range (IQR):\\n\", IQR)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FonNv_3eVKoH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {
        "id": "5LSGANAKVOnB"
      }
    },
    {
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "data_zscore = data.apply(zscore)\n",
        "print(data_zscore.head())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oazdoj2dVPvz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "data1 = np.random.normal(50, 10, 100)\n",
        "data2 = np.random.normal(50, 20, 100)\n",
        "\n",
        "std1 = np.std(data1, ddof=1)\n",
        "std2 = np.std(data2, ddof=1)\n",
        "\n",
        "print(f\"Dataset 1 Standard Deviation: {std1}\")\n",
        "print(f\"Dataset 2 Standard Deviation: {std2}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kEu3qZV3VRzO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "import seaborn as sns\n",
        "\n",
        "cov_matrix = data.cov()\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cov_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Covariance Heatmap\")\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1mxErIT0VTxJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "corr_matrix = data.corr()\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AhPKgFDIVYXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3umz5UPVcHi"
      }
    },
    {
      "source": [
        "data_sample = np.random.randint(10, 100, 50)\n",
        "\n",
        "variance = np.var(data_sample, ddof=1)\n",
        "std_dev = np.std(data_sample, ddof=1)\n",
        "\n",
        "print(f\"Variance: {variance}, Standard Deviation: {std_dev}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rcU1Z1K4VcnE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "import seaborn as sns\n",
        "\n",
        "sns.histplot(data[\"A\"], kde=True)\n",
        "plt.title(\"Skewness and Kurtosis Visualization\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Skewness:\", skew(data[\"A\"]))\n",
        "print(\"Kurtosis:\", kurtosis(data[\"A\"]))\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "T0m40YWhVhtK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "x = np.random.randint(1, 100, 50)\n",
        "y = np.random.randint(1, 100, 50)\n",
        "\n",
        "pearson_corr, _ = pearsonr(x, y)\n",
        "spearman_corr, _ = spearmanr(x, y)\n",
        "\n",
        "print(f\"Pearson Correlation: {pearson_corr}\")\n",
        "print(f\"Spearman Correlation: {spearman_corr}\")\n"
      ],
      "metadata": {
        "id": "HUpcjN0sJE1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}